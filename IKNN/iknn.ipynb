{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recordDS.csv\")\n",
    "transformed_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    qa_array = eval(row['qa_array'])\n",
    "    exercises = qa_array[0]\n",
    "    results = qa_array[1]\n",
    "    for exercise_id, result in zip(exercises, results):\n",
    "        transformed_data.append([user_id, exercise_id, result])\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=['user_id', 'exercise_id', 'result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(transformed_df, test_size=0.2, random_state=42)\n",
    "train_data.to_csv(\"training_set.csv\", index=False)\n",
    "validation_data.to_csv(\"validation_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo para la funcion predict_rating y evaluate_mae fue obtenido de ChatGPT.\n",
    "https://chatgpt.com/share/67323595-4c24-8003-a8ff-14ff143c458a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = train_data.pivot_table(index='user_id', columns='exercise_id', values='result', fill_value=0)\n",
    "\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(interaction_matrix.T)\n",
    "\n",
    "def predict_rating(user_id, exercise_id, n_neighbors=5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    return rating_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 9829 on exercise 1: 0.12994647908989448\n"
     ]
    }
   ],
   "source": [
    "sample_user_id = 9829\n",
    "sample_exercise_id = 1\n",
    "predicted_rating = predict_rating(sample_user_id, sample_exercise_id)\n",
    "print(f\"Predicted rating for user {sample_user_id} on exercise {sample_exercise_id}: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.26218199316911567\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mae(validation_data, n_neighbors=5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "\n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating(user_id, exercise_id, n_neighbors)\n",
    "\n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae\n",
    "\n",
    "# Calculate and print MAE on the validation data\n",
    "mae_value = evaluate_mae(validation_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar cambios y analizar los resultados se usara una fraccion del dataset de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_not_used, validation_data_shortened = train_test_split(validation_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente se esta dando un rating entre 1 y 0 de forma continua, ahora se probara entregarlos de forma discreta haciendo aproximaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_discrete(user_id, exercise_id, n_neighbors=5, rating_threshold=0.5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    if rating_prediction >= rating_threshold:\n",
    "        rating_prediction = 1\n",
    "    else:\n",
    "        rating_prediction = 0\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae_discrete(validation_data, n_neighbors=5, rating_threshold=0.5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "\n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating_discrete(user_id, exercise_id, n_neighbors, rating_threshold)\n",
    "        \n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.5 n_neighbors=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.2317791828170453\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.4 n_neighbors=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.23455208234565236\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, rating_threshold=0.4)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.5 n_neighbors=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.23371158746707477\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, n_neighbors=7, rating_threshold=0.5)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.4 n_neighbors=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.23814822671284605\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, n_neighbors=7, rating_threshold=0.4)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.5 n_neighbors=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.23645875995512475\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, n_neighbors=10, rating_threshold=0.5)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.4 n_neighbors=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.24200455901233892\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, n_neighbors=10, rating_threshold=0.4)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_threshold=0.6 n_neighbors=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.23459829733779583\n"
     ]
    }
   ],
   "source": [
    "mae_value = evaluate_mae_discrete(validation_data_shortened, n_neighbors=5, rating_threshold=0.6)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente se estan utilizando todos los datos de los usuarios para hacer las predicciones, lo cual puede no ser lo mejor considerando que el conocimiento de los usuarios va progresando, y es mas posible que obtenga buenos resultados en los ejercicios que hizo recientemente. Ademas es la informacion que mas habla acerca de si el usuario tendra una pregunta correcta o no. Por esta razon, se repetira lo echo anteriormente pero solo con informacion de los ejercicios que hizo en su ultimo dia registrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recordDS.csv\")\n",
    "\n",
    "transformed_data_time = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    qa_array = eval(row['qa_array'])\n",
    "    create_time = row['create_time']\n",
    "    \n",
    "    exercises = qa_array[0]\n",
    "    results = qa_array[1]\n",
    "    \n",
    "    for exercise_id, result in zip(exercises, results):\n",
    "        transformed_data_time.append([user_id, exercise_id, create_time, result])\n",
    "\n",
    "transformed_time_df = pd.DataFrame(transformed_data_time, columns=['user_id', 'exercise_id', 'create_time','result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_time_df['create_time'] = pd.to_datetime(transformed_time_df['create_time'])\n",
    "transformed_time_df['date'] = transformed_time_df['create_time'].dt.date\n",
    "latest_dates = transformed_time_df.groupby('user_id')['date'].max().reset_index()\n",
    "latest_dates.columns = ['user_id', 'latest_date']\n",
    "filtered_df = pd.merge(transformed_time_df, latest_dates, how='inner', left_on=['user_id', 'date'], right_on=['user_id', 'latest_date'])\n",
    "filtered_df = filtered_df.drop(columns=['date', 'latest_date'])\n",
    "\n",
    "filtered_df.to_csv(\"filtered_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_data, validation_time_data = train_test_split(filtered_df, test_size=0.2, random_state=42)\n",
    "train_time_data.to_csv(\"training_time_set.csv\", index=False)\n",
    "validation_time_data.to_csv(\"validation_time_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = train_time_data.pivot_table(index='user_id', columns='exercise_id', values='result', fill_value=0)\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(interaction_matrix.T)  # Transpose so exercises are the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, exercise_id, n_neighbors=5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae(validation_data, n_neighbors=5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "        \n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating(user_id, exercise_id, n_neighbors)\n",
    "        \n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_value = evaluate_mae(validation_time_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_discrete(user_id, exercise_id, n_neighbors=5, rating_threshold=0.5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    if rating_prediction >= rating_threshold:\n",
    "        rating_prediction = 1\n",
    "    else:\n",
    "        rating_prediction = 0\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae_discrete(validation_data, n_neighbors=5, rating_threshold=0.5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    corrects_1 = 0\n",
    "    corrects_0 = 0\n",
    "    incorrects_1 = 0\n",
    "    incorrects_0 = 0\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "        \n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating_discrete(user_id, exercise_id, n_neighbors, rating_threshold)\n",
    "        \n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "\n",
    "        if actual_result == predicted_result and actual_result == 1:\n",
    "            corrects_1 += 1\n",
    "        elif actual_result == predicted_result and actual_result == 0:\n",
    "            corrects_0 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 1:\n",
    "            incorrects_1 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 0:\n",
    "            incorrects_0 += 1\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae, corrects_0, corrects_1, incorrects_0, incorrects_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.24053330542666393\n",
      " Corrects 0: 2360\n",
      " Corrects 1: 57754\n",
      " Incorrects 0: 19766\n",
      " Incorrects 1: 2312\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete(validation_time_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.24570412497114516\n",
      " Corrects 0: 1076\n",
      " Corrects 1: 58613\n",
      " Incorrects 0: 21050\n",
      " Incorrects 1: 1453\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete(validation_time_data, rating_threshold=0.4)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.2406184718662201\n",
      " Corrects 0: 4604\n",
      " Corrects 1: 55503\n",
      " Incorrects 0: 17522\n",
      " Incorrects 1: 4563\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete(validation_time_data, rating_threshold=0.6)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.25519409966454604\n",
      " Corrects 0: 6857\n",
      " Corrects 1: 52052\n",
      " Incorrects 0: 15269\n",
      " Incorrects 1: 8014\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete(validation_time_data, rating_threshold=0.7)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con dataset equilibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = transformed_df[transformed_df['result'] == 0]\n",
    "correct_df = transformed_df[transformed_df['result'] == 1]\n",
    "\n",
    "correct_sampled_df = correct_df.sample(n=len(incorrect_df), random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([incorrect_df, correct_sampled_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_df.to_csv(\"balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_data, validation_balanced_data = train_test_split(balanced_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix = train_balanced_data.pivot_table(index='user_id', columns='exercise_id', values='result', fill_value=0)\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(interaction_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.41087117208457163\n",
      " Corrects 0: 11182\n",
      " Corrects 1: 41444\n",
      " Incorrects 0: 42868\n",
      " Incorrects 1: 12686\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete(validation_balanced_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con 0s y 1s cambiados por 1s y 2s respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalated_df = transformed_df.copy()\n",
    "escalated_df['result'] = escalated_df['result'].replace({1: 2, 0: 1})\n",
    "escalated_df.to_csv(\"escalated_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_escalated_data, validation_escalated_data = train_test_split(escalated_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix = train_escalated_data.pivot_table(index='user_id', columns='exercise_id', values='result', fill_value=0)\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(interaction_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_discrete_escalated(user_id, exercise_id, n_neighbors=5, rating_threshold=1.5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    if rating_prediction >= rating_threshold:\n",
    "        rating_prediction = 2\n",
    "    else:\n",
    "        rating_prediction = 1\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae_discrete_escalated(validation_data, n_neighbors=5, rating_threshold=1.5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    corrects_1 = 0\n",
    "    corrects_0 = 0\n",
    "    incorrects_1 = 0\n",
    "    incorrects_0 = 0\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "        \n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating_discrete(user_id, exercise_id, n_neighbors, rating_threshold)\n",
    "        \n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "\n",
    "        if actual_result == predicted_result and actual_result == 2:\n",
    "            corrects_1 += 1\n",
    "        elif actual_result == predicted_result and actual_result == 1:\n",
    "            corrects_0 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 2:\n",
    "            incorrects_1 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 1:\n",
    "            incorrects_0 += 1\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae, corrects_0, corrects_1, incorrects_0, incorrects_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.9084130296577081\n",
      " Corrects 0: 35440\n",
      " Corrects 1: 0\n",
      " Incorrects 0: 18631\n",
      " Incorrects 1: 162305\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_discrete_escalated(validation_escalated_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.2910657663303868\n"
     ]
    }
   ],
   "source": [
    "mae_value= evaluate_mae(validation_escalated_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_aprox(user_id, exercise_id, n_neighbors=5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return interaction_matrix.mean().mean()  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return interaction_matrix.mean().mean()  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    if abs(rating_prediction-1) < abs(rating_prediction-2):\n",
    "        rating_prediction = 1\n",
    "    else:\n",
    "        rating_prediction = 2\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae_aprox(validation_data, n_neighbors=5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    corrects_1 = 0\n",
    "    corrects_0 = 0\n",
    "    incorrects_1 = 0\n",
    "    incorrects_0 = 0\n",
    "    \n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        exercise_id = row['exercise_id']\n",
    "        actual_result = row['result']\n",
    "        \n",
    "        # Predict rating using the IKNN model\n",
    "        predicted_result = predict_rating_aprox(user_id, exercise_id, n_neighbors)\n",
    "        \n",
    "        # Append actual and predicted ratings for MAE calculation\n",
    "        actual_ratings.append(actual_result)\n",
    "        predicted_ratings.append(predicted_result)\n",
    "\n",
    "        if actual_result == predicted_result and actual_result == 2:\n",
    "            corrects_1 += 1\n",
    "        elif actual_result == predicted_result and actual_result == 1:\n",
    "            corrects_0 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 2:\n",
    "            incorrects_1 += 1\n",
    "        elif actual_result != predicted_result and actual_result == 1:\n",
    "            incorrects_0 += 1\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "    return mae, corrects_0, corrects_1, incorrects_0, incorrects_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on validation set: 0.2370169413669552\n",
      " Corrects 0: 18592\n",
      " Corrects 1: 146616\n",
      " Incorrects 0: 35479\n",
      " Incorrects 1: 15689\n"
     ]
    }
   ],
   "source": [
    "mae_value, corrects_0, corrects_1, incorrects_0, incorrects_1 = evaluate_mae_aprox(validation_escalated_data)\n",
    "print(f\"Mean Absolute Error (MAE) on validation set: {mae_value}\\n Corrects 0: {corrects_0}\\n Corrects 1: {corrects_1}\\n Incorrects 0: {incorrects_0}\\n Incorrects 1: {incorrects_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo final con todas las mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo para reducir el dataset a la info mas reciente de cada usuario\n",
    "df = pd.read_csv(\"recordDS.csv\")\n",
    "\n",
    "transformed_data_time = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    qa_array = eval(row['qa_array'])\n",
    "    create_time = row['create_time']\n",
    "    \n",
    "    exercises = qa_array[0]\n",
    "    results = qa_array[1]\n",
    "    \n",
    "    for exercise_id, result in zip(exercises, results):\n",
    "        transformed_data_time.append([user_id, exercise_id, create_time, result])\n",
    "\n",
    "transformed_time_df = pd.DataFrame(transformed_data_time, columns=['user_id', 'exercise_id', 'create_time','result'])\n",
    "\n",
    "transformed_time_df['create_time'] = pd.to_datetime(transformed_time_df['create_time'])\n",
    "transformed_time_df['date'] = transformed_time_df['create_time'].dt.date\n",
    "latest_dates = transformed_time_df.groupby('user_id')['date'].max().reset_index()\n",
    "latest_dates.columns = ['user_id', 'latest_date']\n",
    "filtered_df = pd.merge(transformed_time_df, latest_dates, how='inner', left_on=['user_id', 'date'], right_on=['user_id', 'latest_date'])\n",
    "filtered_df = filtered_df.drop(columns=['date', 'latest_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo para balancear el dataset\n",
    "incorrect_df = filtered_df[filtered_df['result'] == 0]\n",
    "correct_df = filtered_df[filtered_df['result'] == 1]\n",
    "\n",
    "correct_sampled_df = correct_df.sample(n=len(incorrect_df), random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([incorrect_df, correct_sampled_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_df.to_csv(\"balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo para cambiar los valores de 0 y 1 a 1 y 2\n",
    "final_df = balanced_df.copy()\n",
    "final_df['result'] = final_df['result'].replace({1: 2, 0: 1})\n",
    "final_df.to_csv(\"final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de los datasets de entrenamiento y validacion\n",
    "train_final_data, validation_final_data = train_test_split(final_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "interaction_matrix = train_final_data.pivot_table(index='user_id', columns='exercise_id', values='result', fill_value=0)\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(interaction_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_aprox(user_id, exercise_id, n_neighbors=5):\n",
    "    if exercise_id not in interaction_matrix.columns:\n",
    "        # If exercise is new or not in the dataset, we may return a default rating\n",
    "        return 2  # Return the global average rating as a fallback\n",
    "\n",
    "    # Find the k-nearest neighbors (similar exercises)\n",
    "    exercise_vector = interaction_matrix[exercise_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(exercise_vector, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the similar exercises and their distances\n",
    "    similar_exercises = interaction_matrix.columns[indices.flatten()]\n",
    "    similarity_scores = 1 - distances.flatten()  # Convert cosine distances to similarities\n",
    "    \n",
    "    # Compute the weighted rating based on similar exercises the user has rated\n",
    "    user_ratings = interaction_matrix.loc[user_id, similar_exercises]\n",
    "    if user_ratings.sum() == 0:\n",
    "        return 2  # Fallback if user hasn't rated similar items\n",
    "\n",
    "    weighted_ratings = user_ratings * similarity_scores\n",
    "    rating_prediction = weighted_ratings.sum() / similarity_scores[user_ratings > 0].sum()\n",
    "    \n",
    "    if abs(rating_prediction-1) < abs(rating_prediction-2):\n",
    "        rating_prediction = 1\n",
    "    else:\n",
    "        rating_prediction = 2\n",
    "    \n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6601\n",
      "Precision: 0.6521\n",
      "Recall: 0.6910\n",
      "F1 Score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "# Assuming `test_final_data` is your test dataset\n",
    "test_final_data = validation_final_data.copy()  # Avoid modifying the original test dataset\n",
    "\n",
    "# Function to predict for all rows in test data\n",
    "def predict_ratings_for_test_data(test_data):\n",
    "    predictions = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        pred = predict_rating_aprox(row['user_id'], row['exercise_id'])\n",
    "        predictions.append(int(pred))\n",
    "    return predictions\n",
    "\n",
    "# Predict ratings for the test set\n",
    "test_final_data['predicted_result'] = predict_ratings_for_test_data(test_final_data)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = test_final_data['result']  # Actual results\n",
    "y_pred = test_final_data['predicted_result']  # Predicted results\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='binary')  # Use 'macro' if it's a multi-class problem\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  exercise_id         create_time  result  predicted_result\n",
      "46322      6131         2041 2020-12-03 14:40:00       1                 2\n",
      "20928      1805         2483 2020-06-11 10:24:00       2                 2\n",
      "105803    15090          954 2022-01-22 21:33:00       1                 1\n",
      "96138     10372         1739 2021-12-10 05:55:00       1                 1\n",
      "175764    15165         2483 2022-01-26 11:26:00       1                 2\n",
      "...         ...          ...                 ...     ...               ...\n",
      "55577      1816         2425 2020-06-11 10:39:00       1                 2\n",
      "29198      9680         1321 2021-08-17 22:17:00       1                 2\n",
      "94211      1811         1020 2020-04-09 11:30:00       1                 2\n",
      "203416     7575         1296 2021-01-31 22:45:00       2                 2\n",
      "123192     9601         1672 2021-08-14 13:35:00       1                 1\n",
      "\n",
      "[44138 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_final_data)\n",
    "test_final_data.to_csv(\"test_final_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
